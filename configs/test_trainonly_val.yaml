# Test Configuration: Train-Only Validation
# Uses training images split into train/val to test if validation data is the problem
# If this achieves good val accuracy, it confirms the original val data is mislabeled

data_root: /mnt/nvme_data/imagenet_subset_trainonly
img_size: 224

batch_size: 256
num_workers: 8
pin_memory: true
persistent_workers: true
prefetch_factor: 2

model_name: resnet50
pretrained: true  # Use pretrained for faster convergence
num_classes: 100
compile_model: false

mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# Quick test - 10 epochs should be enough
epochs: 10
optimizer: sgd
lr: 0.01  # Lower LR for fine-tuning
momentum: 0.9
weight_decay: 0.0001
lr_scheduler: cosine
warmup_epochs: 1
max_epochs: 10

precision: 16-mixed

random_crop: true
random_horizontal_flip: true
auto_augment: null
mixup_alpha: 0.0
cutmix_alpha: 0.0
label_smoothing: 0.1

use_ema: false
gradient_clip_val: null

log_every_n_steps: 20
val_check_interval: 1.0

save_top_k: 3
monitor: val/acc1
mode: max

devices: 1
strategy: auto
sync_batchnorm: false

seed: 42
deterministic: false

# Expected results if validation data was the problem:
# - Val accuracy should be HIGH (60-80%) since val images are correctly labeled
# - Train and val should both improve together
# - No massive train/val gap
