# ResNet Strikes Back (A2) Training Recipe
# Based on: https://arxiv.org/abs/2110.00476
# Target: ~80.4% top-1 accuracy on ImageNet with ResNet-50

# Data settings
data_root: /mnt/imagenet-data/imagenet  # Mounted EBS volume with ImageNet data
batch_size: 256  # Per GPU (8 GPUs = 2048 effective batch) - RSB A2 standard
num_workers: 24  # Per GPU (8 GPUs * 24 = 192 workers)
pin_memory: true
persistent_workers: true
prefetch_factor: 6  # Very aggressive prefetching to saturate GPUs

# Model settings
model_name: resnet50
pretrained: false
num_classes: 1000
compile_model: true  # PyTorch 2.0+ compilation for speed

# Image preprocessing (ImageNet standard)
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# Training hyperparameters (ResNet Strikes Back A2 recipe)
epochs: 300  # RSB A2 uses 300 epochs (gets ~79.8%)
optimizer: lamb  # LAMB optimizer (critical for RSB A2)
lr: 5.0e-3  # RSB A2 base LR (5e-3)
momentum: 0.9  # Not used with LAMB
weight_decay: 0.02  # RSB A2 uses 0.02-0.03
lr_scheduler: cosine  # Cosine decay
warmup_epochs: 5  # RSB A2 uses 5-10 epochs warmup
max_epochs: 300  # Total training epochs
cosine_t_max: 295  # Decay over 295 epochs (300 - 5 warmup)
eta_min: 0.0  # Cosine to 0 (RSB A2)

# Mixed precision training
precision: 16-mixed  # Faster training with minimal accuracy loss

# Augmentation (ResNet Strikes Back A2 recipe)
random_crop: true
random_horizontal_flip: true
auto_augment: randaugment  # RandAugment (Mâ‰ˆ7-9)
random_erasing: 0.25  # Random Erasing p=0.25 (RSB A2)
mixup_alpha: 0.2  # Mixup (ResNet Strikes Back A2)
cutmix_alpha: 1.0  # CutMix (ResNet Strikes Back A2)
label_smoothing: 0.1  # Label smoothing (not used with BCE+mixup/cutmix)

# Regularization
use_ema: false  # Not used in base ResNet Strikes Back
gradient_clip_val: null

# Logging
log_every_n_steps: 100
val_check_interval: 1.0  # Validate every epoch

# Checkpointing
save_top_k: 5
monitor: val/acc1
mode: max

# Distributed training (for multi-GPU/multi-node)
devices: 8  # 8x A100 40GB GPUs
num_nodes: 1
strategy: ddp
sync_batchnorm: true

# Reproducibility
seed: 42
deterministic: false  # Set to true for reproducibility (slower)

# Notes:
# - This is the A2 recipe from ResNet Strikes Back
# - Expected accuracy: ~80.4% top-1 on ImageNet
# - Training time: ~600 epochs (longer than standard 90)
# - For faster training, use 90-100 epochs with slightly lower accuracy (~78-79%)
# - LR scaling: If using larger batch size, scale LR linearly
#   Example: batch_size=512 -> lr=1.0, batch_size=1024 -> lr=2.0
